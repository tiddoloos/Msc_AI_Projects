{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3: Q5 / Q6 / Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "import math\n",
    "from numpy import random\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- assignment 1 --\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def load_synth(num_train=60_000, num_val=10_000, seed=0):\n",
    "    \"\"\"\n",
    "    Load some very basic synthetic data that should be easy to classify. Two features, so that we can plot the\n",
    "    decision boundary (which is an ellipse in the feature space).\n",
    "    :param num_train: Number of training instances\n",
    "    :param num_val: Number of test/validation instances\n",
    "    :param num_features: Number of features per instance\n",
    "    :return: Two tuples and an integer: (xtrain, ytrain), (xval, yval), num_cls. The first contains a matrix of training\n",
    "     data with 2 features as a numpy floating point array, and the corresponding classification labels as a numpy\n",
    "     integer array. The second contains the test/validation data in the same format. The last integer contains the\n",
    "     number of classes (this is always 2 for this function).\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    THRESHOLD = 0.6\n",
    "    quad = np.asarray([[1, -0.05], [1, .4]])\n",
    "\n",
    "    ntotal = num_train + num_val\n",
    "\n",
    "    x = np.random.randn(ntotal, 2)\n",
    "\n",
    "    # compute the quadratic form\n",
    "    q = np.einsum('bf, fk, bk -> b', x, quad, x)\n",
    "    y = (q > THRESHOLD).astype(np.int)\n",
    "\n",
    "    return (x[:num_train, :], y[:num_train]), (x[num_train:, :], y[num_train:]), 2\n",
    "\n",
    "def load_mnist(final=False, flatten=True):\n",
    "    \"\"\"\n",
    "    Load the MNIST data.\n",
    "    :param final: If true, return the canonical test/train split. If false, split some validation data from the training\n",
    "       data and keep the test data hidden.\n",
    "    :param flatten: If true, each instance is flattened into a vector, so that the data is returns as a matrix with 768\n",
    "        columns. If false, the data is returned as a 3-tensor preserving each image as a matrix.\n",
    "    :return: Two tuples and an integer: (xtrain, ytrain), (xval, yval), num_cls. The first contains a matrix of training\n",
    "     data and the corresponding classification labels as a numpy integer array. The second contains the test/validation\n",
    "     data in the same format. The last integer contains the number of classes (this is always 2 for this function).\n",
    "     \"\"\"\n",
    "\n",
    "    if not os.path.isfile('mnist.pkl'):\n",
    "        init()\n",
    "\n",
    "    xtrain, ytrain, xtest, ytest = load()\n",
    "    xtl, xsl = xtrain.shape[0], xtest.shape[0]\n",
    "\n",
    "    if flatten:\n",
    "        xtrain = xtrain.reshape(xtl, -1)\n",
    "        xtest  = xtest.reshape(xsl, -1)\n",
    "\n",
    "    if not final: # return the flattened images\n",
    "        return (xtrain[:-5000], ytrain[:-5000]), (xtrain[-5000:], ytrain[-5000:]), 10\n",
    "\n",
    "    return (xtrain, ytrain), (xtest, ytest), 10\n",
    "\n",
    "# Numpy-only MNIST loader. Courtesy of Hyeonseok Jung\n",
    "# https://github.com/hsjeong5/MNIST-for-Numpy\n",
    "\n",
    "filename = [\n",
    "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "def download_mnist():\n",
    "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "    for name in filename:\n",
    "        print(\"Downloading \"+name[1]+\"...\")\n",
    "        request.urlretrieve(base_url+name[1], name[1])\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def save_mnist():\n",
    "    mnist = {}\n",
    "    for name in filename[:2]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "    for name in filename[-2:]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    with open(\"mnist.pkl\", 'wb') as f:\n",
    "        pickle.dump(mnist,f)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "def init():\n",
    "    download_mnist()\n",
    "    save_mnist()\n",
    "\n",
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, W1, W2, b1, b2, lr):\n",
    "        self.W1 = W1\n",
    "        self.W2 = W2\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self.learn = lr\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        X = np.clip(X, -500, 500 )\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    \n",
    "    def forward(self, x, nn):\n",
    "        Z1 = np.dot(self.W1, x) + self.b1\n",
    "        A1 = nn.sigmoid(Z1)\n",
    "        Z2 = np.dot(self.W2, A1) + self.b2\n",
    "        A2 = nn.softmax(Z2)\n",
    "        return Z1, A1, A2\n",
    "    \n",
    "    \n",
    "    def backprop(self, A1, A2, x, y):\n",
    "        m = x.shape[1]\n",
    "        dz2 = A2 - y\n",
    "        dW2 = np.dot(dz2, A1.T) * (1/m)\n",
    "        db2 = np.sum(dz2, axis =1, keepdims = True) * (1/m)\n",
    "        dZ1 = np.dot(self.W2.T, dz2) * (1 - np.power(A1, 2))\n",
    "        dW1 = np.dot(dZ1, x.T) * (1/m)\n",
    "        db1 = np.sum(dZ1, axis =1, keepdims = True) * (1/m)\n",
    "        return dW1, dW2, db1, db2\n",
    "\n",
    "    def update_weights(self, dW1, dW2, db1, db2):\n",
    "        self.W1 = self.W1 - self.learn * dW1\n",
    "        self.b1 = self.b1 - self.learn * db1\n",
    "        self.W2 = self.W2 - self.learn * dW2\n",
    "        self.b2 = self.b2 - self.learn * db2\n",
    "\n",
    "    def loss(self, y_pred, y):\n",
    "        return -np.log(y_pred[np.where(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(nn, x, y, val=False):\n",
    "    #training data\n",
    "    Z1, A1, A2 = nn.forward(x, nn)\n",
    "    loss = nn.loss(A2, y)\n",
    "    if val==False:\n",
    "        dW1, dW2, db1, db2 = nn.backprop(A1, A2, x, y)\n",
    "        nn.update_weights(dW1, dW2, db1, db2)\n",
    "    return loss\n",
    "\n",
    "def sgd(nn, xtrain, ytrain, xval, yval, epochs):\n",
    "    loss_list_xtrain = []\n",
    "    loss_list_xval = []\n",
    "    epoch_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    for i in range(1,epochs+1,):\n",
    "        print('Epoch=', i)\n",
    "        loss_xtrain = []\n",
    "        loss_xval = []\n",
    "        \n",
    "        print('...training...')\n",
    "        for x, y in zip(xtrain.T, ytrain.T):\n",
    "            x = np.array(x).reshape(x.shape[0],1)\n",
    "            y = np.array(y).reshape(y.shape[0],1)\n",
    "            loss_xt = cycle(nn, x, y)\n",
    "            loss_xtrain.append(loss_xt)\n",
    "    \n",
    "        print('...validating...')\n",
    "        for x, y in zip(xval.T, yval.T):\n",
    "            xval = np.array(x).reshape(x.shape[0],1)\n",
    "            yval = np.array(y).reshape(y.shape[0],1)\n",
    "            loss_val = cycle(nn, xval, yval, val=True)\n",
    "            loss_xval.append(loss_val)\n",
    "\n",
    "        loss_list_xtrain.append(np.average(loss_xtrain))\n",
    "        loss_list_xval.append(np.average(loss_xval))\n",
    "        epoch_list.append(i)\n",
    "        \n",
    "    return loss_list_xtrain, loss_list_xval, epoch_list\n",
    "\n",
    "def count_trues(nn, val_list, true_index):\n",
    "    pred_index = [np.argmax(i) for i in val_list]\n",
    "    count = 0\n",
    "    for i in range(len(true_index)):\n",
    "        if pred_index[i]==true_index[i]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_accuracy(nn, xval, y_or):\n",
    "    val_list = []\n",
    "    print(xval.T)\n",
    "    for x in xval.T:\n",
    "        xval = np.array(x).reshape(x.shape[0],1)\n",
    "        Z1, A1, A2 = nn.forward(xval, nn)\n",
    "        val_list.append(A2)\n",
    "    count = count_trues(nn, val_list, y_or)\n",
    "    return count/len(y_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Download complete.\n",
      "Save complete.\n",
      "(784, 55000) (10, 55000) (784, 5000) (10, 5000)\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "(xtrain, ytrain), (xval, yval), num_cls = load_mnist()\n",
    "y_original = yval\n",
    "\n",
    "xtrain = np.array(xtrain).T\n",
    "xval = np.array(xval).T\n",
    "\n",
    "y_train = np.zeros((ytrain.shape[0], ytrain.max()+1), dtype=np.float32)\n",
    "y_train[np.arange(ytrain.shape[0]), ytrain] = 1\n",
    "y_val = np.zeros((yval.shape[0], yval.max()+1), dtype=np.float32)\n",
    "y_val[np.arange(yval.shape[0]), yval] = 1\n",
    "\n",
    "ytrain = np.array(y_train).T\n",
    "yval = np.array(y_val).T\n",
    "\n",
    "#normalize\n",
    "xtrain = xtrain/255\n",
    "xval = xval/255\n",
    "\n",
    "print(xtrain.shape, ytrain.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 1\n",
      "...training...\n",
      "...validating...\n",
      "Epoch= 2\n",
      "...training...\n",
      "...validating...\n",
      "Epoch= 3\n",
      "...training...\n",
      "...validating...\n",
      "Epoch= 4\n",
      "...training...\n",
      "...validating...\n",
      "Epoch= 5\n",
      "...training...\n",
      "...validating...\n"
     ]
    }
   ],
   "source": [
    "#initialize(nn-> inputs-300-10)\n",
    "W1 = np.random.randn(300, xtrain.shape[0])\n",
    "W2 = np.random.randn(10, 300)\n",
    "b1 = np.zeros([300,1])\n",
    "b2 = np.zeros([10,1])\n",
    "lr = 0.01\n",
    "nn = NeuralNet(W1, W2, b1, b2, lr)\n",
    "epochs = 5\n",
    "\n",
    "loss_list_xtrain, loss_list_xval, epoch_list = sgd(nn, xtrain, ytrain, xval, yval, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1 = loss_list_xtrain\n",
    "x1 = epoch_list\n",
    "plt.plot(x1, y1, label = \"Loss Training Set\")\n",
    "y2 = loss_list_xval\n",
    "x2 = epoch_list\n",
    "plt.plot(x2, y2, label = \"Loss Validation Set\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss on training and validation set')\n",
    "plt.xticks(np.arange(min(x1), max(x1)+1, 1.0))\n",
    "plt.legend()\n",
    "plt.savefig('Q7,1: training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 Minibatch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this data block before runnning the bathc gradient descent code block\n",
    "(xtrain, ytrain), (xval, yval), num_cls = load_mnist()\n",
    "y_original = yval\n",
    "\n",
    "xtrain = np.array(xtrain).T\n",
    "xval = np.array(xval).T\n",
    "\n",
    "y_train = np.zeros((ytrain.shape[0], ytrain.max()+1), dtype=np.float32)\n",
    "y_train[np.arange(ytrain.shape[0]), ytrain] = 1\n",
    "y_val = np.zeros((yval.shape[0], yval.max()+1), dtype=np.float32)\n",
    "y_val[np.arange(yval.shape[0]), yval] = 1\n",
    "\n",
    "ytrain = np.array(y_train).T\n",
    "yval = np.array(y_val).T\n",
    "\n",
    "#normalize\n",
    "xtrain = xtrain/255\n",
    "xval = xval/255\n",
    "\n",
    "print(xtrain.shape, ytrain.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(data, labels, batch_size,shuffle=True):\n",
    "        n_features, n_samples = data.shape\n",
    "\n",
    "        batch_indices = np.arange(0, n_samples, batch_size)\n",
    "\n",
    "        if shuffle:\n",
    "            permutation = np.random.permutation(n_samples)\n",
    "            data = data[:, permutation]\n",
    "            labels = labels[:, permutation]\n",
    "        \n",
    "        for i in range(len(xtrain)):\n",
    "            for i in batch_indices:\n",
    "                X = data[:, i:i + batch_size]\n",
    "                Y = labels[:, i:i + batch_size]\n",
    "            return X, Y\n",
    "def shuffle(x, y):\n",
    "    p = np.random.permutation(len(y))\n",
    "    return x[p], y[p]\n",
    "\n",
    "def minibatch_gd(nn, xtrain, ytrain, xval, yval, minibatch_size, epochs):\n",
    "    \n",
    "    loss_list_xtrain = []\n",
    "    loss_list_xval = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for i in range(1,epochs+1,):\n",
    "        print('Epoch=', i)\n",
    "        loss_xtrain = []\n",
    "        loss_xval = []\n",
    "        \n",
    "        #loop and create batches:\n",
    "        for j in range(0, xtrain.shape[1], minibatch_size):\n",
    "            xbatch, ybatch = make_batches(xtrain, ytrain, 500, shuffle=True)\n",
    "            #train on batches\n",
    "            loss_xt = cycle(nn, xbatch, ybatch)\n",
    "            loss_xtrain.append(loss_xt)\n",
    "            for x, y in zip(xval.T, yval.T):\n",
    "                xval = np.array(x).reshape(x.shape[0],1)\n",
    "                yval = np.array(y).reshape(y.shape[0],1)\n",
    "                loss_val = cycle(nn, xval, yval, val=True)\n",
    "                loss_xval.append(loss_val)\n",
    "            loss_list_xtrain.append(np.average(loss_xtrain))\n",
    "            loss_list_xval.append(np.average(loss_xval))\n",
    "        epoch_list.append(i)\n",
    "        \n",
    "\n",
    "    return loss_list_xtrain, loss_list_xval, epoch_list\n",
    "random.seed(1)\n",
    "W1 = np.random.randn(300, xtrain.shape[0])\n",
    "W2 = np.random.randn(10, 300)\n",
    "b1 = np.zeros([300,1])\n",
    "b2 = np.zeros([10,1])\n",
    "lr = 0.01\n",
    "nn = NeuralNet(W1, W2, b1, b2, lr)\n",
    "epochs = 5\n",
    "minibatch_size = 100\n",
    "batch_loss_list_xtrain, batch_loss_list_xval, epoch_list = minibatch_gd(nn, xtrain, ytrain, xval, yval, minibatch_size, epochs)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = []\n",
    "for i in range(1,len(batch_loss_list_xtrain)+1,1):\n",
    "    x_axis.append(i*(epochs/len(batch_loss_list_xtrain)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = batch_loss_list_xtrain\n",
    "x1 = x_axis\n",
    "plt.plot(x1, y1, label = \"Training\")\n",
    "\n",
    "y2 = batch_loss_list_xval\n",
    "x2 = x_axis\n",
    "plt.plot(x2, y2, label = \"validation\")\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss during epochs with batch gradient descent')\n",
    "plt.xticks(np.arange(0, 6, 1.0))\n",
    "plt.legend()\n",
    "plt.savefig('Q6,50batchloss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_minibatch = get_accuracy(nn, xval, y_original)\n",
    "print(acc_minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize(nn-> inputs-300-10)\n",
    "loss_xtrain_av=[]\n",
    "loss_xval_av=[]\n",
    "for j in range(1,5):\n",
    "    W1 = np.random.randn(300, xtrain.shape[0])\n",
    "    W2 = np.random.randn(10, 300)\n",
    "    b1 = np.zeros([300,1])\n",
    "    b2 = np.zeros([10,1])\n",
    "    lr = 0.01\n",
    "    nn = NeuralNet(W1, W2, b1, b2, lr)\n",
    "    epochs = 5\n",
    "    loss_list_xtrain, loss_list_xval, epoch_list = sgd(nn, xtrain, ytrain, xval, yval, epochs)\n",
    "    av_loss_xtrain = []\n",
    "    av_loss_xval = []\n",
    "\n",
    "    for i in range(len(loss_list_xtrain)):\n",
    "        av_loss_xtrain.append(loss_list_xtrain[i])\n",
    "        av_loss_xval.append(loss_list_xval[i])\n",
    "    \n",
    "    loss_xtrain_av.append(av_loss_xtrain)\n",
    "    loss_xval_av.append(av_loss_xval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = loss_xval_av[0]\n",
    "x1 = epoch_list\n",
    "plt.plot(x1, y1, label = \"run1\")\n",
    "\n",
    "y2 = loss_xval_av[1]\n",
    "x2 = epoch_list\n",
    "plt.plot(x2, y2, label = \"run2\")\n",
    "\n",
    "y3 = loss_xval_av[2]\n",
    "x3 = epoch_list\n",
    "plt.plot(x3, y3, label = \"run3\")\n",
    "\n",
    "y4 = loss_xval_av[3]\n",
    "x4 = epoch_list\n",
    "plt.plot(x4, y4, label = \"run4\")\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Average loss of 4 runs on validation set')\n",
    "plt.xticks(np.arange(min(x1), max(x1)+1, 1.0))\n",
    "plt.legend()\n",
    "plt.savefig('Q7,2 validation loss of 4 runs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_epoch1 = []\n",
    "std_epoch2 = []\n",
    "std_epoch3 = []\n",
    "std_epoch4 = []\n",
    "std_epoch5 = []\n",
    "for i in loss_xval_av:\n",
    "    std_epoch1.append(i[0])\n",
    "    std_epoch2.append(i[1])\n",
    "    std_epoch3.append(i[2])\n",
    "    std_epoch4.append(i[3])\n",
    "    std_epoch5.append(i[4])\n",
    "    \n",
    "std1 = np.std(std_epoch1)\n",
    "std2 = np.std(std_epoch2)\n",
    "std3 = np.std(std_epoch3)\n",
    "std4 = np.std(std_epoch4)\n",
    "std5 = np.std(std_epoch5)\n",
    "stds = [std1, std2, std3, std4, std5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = stds\n",
    "x1 = epoch_list\n",
    "plt.plot(x1, y1, label = \"std\")\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Standaard deviation')\n",
    "plt.title('Standard deviation of the average loss during of the four different runs')\n",
    "plt.xticks(np.arange(min(x1), max(x1)+1, 1.0))\n",
    "plt.legend()\n",
    "plt.savefig('Q7,2 std')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize(nn-> inputs-300-10)\n",
    "loss_xtrain_av=[]\n",
    "loss_xval_av=[]\n",
    "acc = []\n",
    "lr = 0.002\n",
    "for j in range(1,11):\n",
    "    W1 = np.random.randn(300, xtrain.shape[0])\n",
    "    W2 = np.random.randn(10, 300)\n",
    "    b1 = np.zeros([300,1])\n",
    "    b2 = np.zeros([10,1])\n",
    "    nn = NeuralNet(W1, W2, b1, b2, lr)\n",
    "    epochs = 5\n",
    "    loss_list_xtrain, loss_list_xval, epoch_list = sgd(nn, xtrain, ytrain, xval, yval, epochs)\n",
    "    av_loss_xtrain = []\n",
    "    av_loss_xval = []\n",
    "\n",
    "    for i in range(len(loss_list_xtrain)):\n",
    "        av_loss_xtrain.append(loss_list_xtrain[i])\n",
    "        av_loss_xval.append(loss_list_xval[i])\n",
    "    \n",
    "    loss_xtrain_av.append(av_loss_xtrain)\n",
    "    loss_xval_av.append(av_loss_xval)\n",
    "    acc.append(get_accuracy(nn, xval, y_original))\n",
    "    lr += 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrates = [0.002, 0.004, 0.006, 0.008, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = acc\n",
    "x1 = learningrates\n",
    "plt.plot(x1, y1, label = \"accuracy\")\n",
    "\n",
    "plt.xlabel('Learning Rates')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of diffrent learning reates after 5 epochs on the evaluation data')\n",
    "plt.xticks(np.arange(min(x1), max(x1)+0.002, 0.002))\n",
    "plt.yticks(np.arange(0.94, 0.97, 0.01))\n",
    "plt.legend()\n",
    "plt.savefig('new:Q7,3 LearningRates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y1 = loss_xval_av[0][:3:]\n",
    "x1 = epoch_list[:3:]\n",
    "plt.plot(x1, y1, label = \"0.002\")\n",
    "\n",
    "y2 = loss_xval_av[1][:3:]\n",
    "x2 = epoch_list[:3:]\n",
    "plt.plot(x2, y2, label = \"0.004\")\n",
    "\n",
    "y3 = loss_xval_av[2][:3:]\n",
    "x3 = epoch_list[:3:]\n",
    "plt.plot(x3, y3, label = \"0.006\")\n",
    "\n",
    "y4 = loss_xval_av[3][:3:]\n",
    "x4 = epoch_list[:3:]\n",
    "plt.plot(x4, y4, label = \"0.008\")\n",
    "\n",
    "y5 = loss_xval_av[4][:3:]\n",
    "x5 = epoch_list[:3:]\n",
    "plt.plot(x5, y5, label = \"0.010\")\n",
    "\n",
    "y6 = loss_xval_av[5][:3:]\n",
    "x6 = epoch_list[:3:]\n",
    "plt.plot(x6, y6, label = \"0.012\")\n",
    "\n",
    "y7 = loss_xval_av[6][:3:]\n",
    "x7 = epoch_list[:3:]\n",
    "plt.plot(x7, y7, label = \"0.014\")\n",
    "\n",
    "y8 = loss_xval_av[7][:3:]\n",
    "x8 = epoch_list[:3:]\n",
    "plt.plot(x8, y8, label = \"0.016\")\n",
    "\n",
    "y9 = loss_xval_av[8][:3:]\n",
    "x9 = epoch_list[:3:]\n",
    "plt.plot(x7, y7, label = \"0.018\")\n",
    "\n",
    "y10 = loss_xval_av[9][:3:]\n",
    "x1 = epoch_list\n",
    "x10 = epoch_list\n",
    "plt.plot(x8, y8, label = \"0.020\")\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss during 5 epochs of with different learning rates')\n",
    "plt.yticks(np.arange(0, 0.45, 0.05))\n",
    "plt.xticks(np.arange(min(x1), 3.5, 0.5))\n",
    "plt.legend()\n",
    "plt.savefig('Q7,3 Learning and losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "(xtrain, ytrain), (xval, yval), num_cls = load_mnist(final=True)\n",
    "print(xtrain)\n",
    "print(ytrain)\n",
    "print(xval)\n",
    "print(yval)\n",
    "y_original = yval\n",
    "\n",
    "xtrain = np.array(xtrain).T\n",
    "xval = np.array(xval).T\n",
    "\n",
    "y_train = np.zeros((ytrain.shape[0], ytrain.max()+1), dtype=np.float32)\n",
    "y_train[np.arange(ytrain.shape[0]), ytrain] = 1\n",
    "y_val = np.zeros((yval.shape[0], yval.max()+1), dtype=np.float32)\n",
    "y_val[np.arange(yval.shape[0]), yval] = 1\n",
    "\n",
    "ytrain = np.array(y_train).T\n",
    "yval = np.array(y_val).T\n",
    "\n",
    "#normalize\n",
    "xtrain = xtrain/255\n",
    "xval = xval/255\n",
    "\n",
    "print(xtrain.shape, ytrain.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize(nn-> inputs-300-10)\n",
    "W1 = np.random.randn(300, xtrain.shape[0])\n",
    "W2 = np.random.randn(10, 300)\n",
    "b1 = np.zeros([300,1])\n",
    "b2 = np.zeros([10,1])\n",
    "lr = 0.01\n",
    "nn = NeuralNet(W1, W2, b1, b2, lr)\n",
    "epochs = 5\n",
    "loss_list_xtrain, loss_list_xval, epoch_list = sgd(nn, xtrain, ytrain, xval, yval, epochs)\n",
    "acc_final = get_accuracy(nn, xval, y_original)\n",
    "print(acc_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
